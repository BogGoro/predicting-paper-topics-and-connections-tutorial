{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cde2871c",
      "metadata": {
        "id": "cde2871c"
      },
      "source": [
        "# Tutorial: Node Classification and Link Prediction in Citation Networks\n",
        "\n",
        "## Applying Graph Machine Learning to Academic Paper Analysis\n",
        "\n",
        "**Authors**: Denis Troegubov  \n",
        "**Date**: December 2025  \n",
        "**GitHub**: [Link](https://github.com/BogGoro/predicting-paper-topics-and-connections-tutorial)\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome to this hands-on tutorial on **Graph Machine Learning**!  \n",
        "In this notebook, we will implement and compare two popular **Graph Neural Network (GNN)** architectures **GraphSAGE** and **GATv2** on the **Cora** citation network dataset.\n",
        "\n",
        "We will solve two key graph learning tasks:\n",
        "\n",
        "1. **Node Classification**: Predicting the research topic of academic papers  \n",
        "2. **Link Prediction**: Recommending potential citations between papers  \n",
        "\n",
        "The notebook is structured as follows:\n",
        "- Data exploration and visualization\n",
        "- Implementation of modular GNN systems for each task\n",
        "- Training and evaluation pipelines\n",
        "- **Comparative analysis** across 100 independent runs to assess model stability and performance\n",
        "\n",
        "We use **PyTorch Geometric (PyG)** for graph learning and include **statistical tests** to validate differences between models.\n",
        "\n",
        "### Prerequisites\n",
        "- Basic knowledge of Python and PyTorch\n",
        "- Familiarity with neural networks\n",
        "- No prior experience with graphs required\n",
        "\n",
        "Let's get started"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f523f2c",
      "metadata": {
        "id": "5f523f2c"
      },
      "source": [
        "1. Environment Setup\n",
        "\n",
        "We begin by installing and importing necessary libraries, setting random seeds for reproducibility, and checking GPU availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d73e13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81d73e13",
        "outputId": "b01e998a-2be7-4906-cb6d-52299154dfb8"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch Geometric if you are running in colab\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a406799f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a406799f",
        "outputId": "bdfa4e64-7362-4915-9b65-b5e0035a0fb5"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# PyTorch Geometric\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import SAGEConv, GCNConv\n",
        "from torch_geometric.utils import negative_sampling, to_networkx\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create directory for visualizations\n",
        "try:\n",
        "    os.mkdir(\"images\")\n",
        "except Exception:\n",
        "    print(\"Directory already exists\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10667a9c",
      "metadata": {
        "id": "10667a9c"
      },
      "source": [
        "## 2. Understanding the Data: Cora Dataset\n",
        "\n",
        "### What is Cora?\n",
        "The Cora dataset is a classic citation network consisting of machine learning papers. It's widely used as a benchmark in graph ML research.\n",
        "\n",
        "### Dataset Statistics:\n",
        "- **Nodes**: 2,708 academic papers\n",
        "- **Edges**: 10,556 citation links (directed)\n",
        "- **Features**: 1,433-dimensional binary word vectors (bag-of-words)\n",
        "- **Classes**: 7 research topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3bb708",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3bb708",
        "outputId": "70743953-32a9-4613-c634-d7f12e3387e1"
      },
      "outputs": [],
      "source": [
        "# Load the Cora dataset\n",
        "dataset = Planetoid(root=\"/tmp/Cora\", name=\"Cora\")\n",
        "data = dataset[0]\n",
        "\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Dataset: {dataset}\")\n",
        "print(f\"Number of graphs: {len(dataset)}\")\n",
        "print(f\"Number of nodes: {data.num_nodes}\")\n",
        "print(f\"Number of edges: {data.num_edges}\")\n",
        "print(f\"Number of features: {data.num_features}\")\n",
        "print(f\"Number of classes: {dataset.num_classes}\")\n",
        "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
        "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
        "print(f\"Is undirected: {data.is_undirected()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2ca72d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "fc2ca72d",
        "outputId": "b3562a5c-f366-460b-be1d-8242bba144b1"
      },
      "outputs": [],
      "source": [
        "# Visualize the class distribution\n",
        "class_names = [\n",
        "    \"Case-Based\",\n",
        "    \"Genetic Algorithms\",\n",
        "    \"Neural Networks\",\n",
        "    \"Probabilistic Methods\",\n",
        "    \"Reinforcement Learning\",\n",
        "    \"Rule Learning\",\n",
        "    \"Theory\",\n",
        "]\n",
        "\n",
        "class_counts = torch.bincount(data.y).numpy()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(class_names, class_counts, color=sns.color_palette(\"husl\", 7))\n",
        "plt.title(\n",
        "    \"Distribution of Paper Topics in Cora Dataset\", fontsize=14, fontweight=\"bold\"\n",
        ")\n",
        "plt.xlabel(\"Research Topic\", fontsize=12)\n",
        "plt.ylabel(\"Number of Papers\", fontsize=12)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "# Add count labels on bars\n",
        "for bar, count in zip(bars, class_counts):\n",
        "    height = bar.get_height()\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2.0,\n",
        "        height + 5,\n",
        "        f\"{count}\",\n",
        "        ha=\"center\",\n",
        "        va=\"bottom\",\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"images/class_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a20da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "d9a20da1",
        "outputId": "3c7339c9-178a-442b-b234-188af1271c39"
      },
      "outputs": [],
      "source": [
        "# Visualize a subgraph of the citation network\n",
        "def visualize_citation_subgraph(data, num_nodes=100):\n",
        "    \"\"\"Visualize a small subgraph of the citation network\"\"\"\n",
        "    # Take first num_nodes nodes\n",
        "    subgraph_nodes = torch.arange(num_nodes)\n",
        "\n",
        "    # Create mask for edges between these nodes\n",
        "    mask = (data.edge_index[0] < num_nodes) & (data.edge_index[1] < num_nodes)\n",
        "    subgraph_edges = data.edge_index[:, mask]\n",
        "\n",
        "    # Create subgraph\n",
        "    subgraph = Data(\n",
        "        x=data.x[:num_nodes], edge_index=subgraph_edges, y=data.y[:num_nodes]\n",
        "    )\n",
        "\n",
        "    # Convert to NetworkX for visualization\n",
        "    G = to_networkx(subgraph, to_undirected=True)\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Node colors by class\n",
        "    node_colors = [data.y[i].item() for i in range(num_nodes)]\n",
        "\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw_networkx_nodes(\n",
        "        G, pos, node_size=50, node_color=node_colors, cmap=plt.cm.Set2, alpha=0.8\n",
        "    )\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.2, width=0.5)\n",
        "\n",
        "    plt.title(\n",
        "        f\"Citation Network Subgraph (First {num_nodes} Papers)\",\n",
        "        fontsize=14,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Create legend for classes\n",
        "    legend_elements = [\n",
        "        plt.Line2D(\n",
        "            [0],\n",
        "            [0],\n",
        "            marker=\"o\",\n",
        "            color=\"w\",\n",
        "            markerfacecolor=plt.cm.Set2(i / 7),\n",
        "            markersize=10,\n",
        "            label=class_names[i],\n",
        "        )\n",
        "        for i in range(7)\n",
        "    ]\n",
        "    plt.legend(\n",
        "        handles=legend_elements,\n",
        "        title=\"Research Topics\",\n",
        "        bbox_to_anchor=(1.05, 1),\n",
        "        loc=\"upper left\",\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"images/citation_subgraph.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "# Visualize subgraph\n",
        "G = visualize_citation_subgraph(data, num_nodes=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5abcdc8b",
      "metadata": {
        "id": "5abcdc8b"
      },
      "source": [
        "## 3. Graph Neural Networks: Core Concepts\n",
        "GNNs extend deep learning to graph-structured data through **message passing**:\n",
        "1. Gather neighbor features\n",
        "2. Aggregate them (sum, mean, max)\n",
        "3. Update node representations\n",
        "\n",
        "We implement:\n",
        "- **GraphSAGE**: Inductive, scalable, supports neighborhood sampling\n",
        "- **GATv2**: Uses attention to weigh neighbor importance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6407f203",
      "metadata": {
        "id": "6407f203"
      },
      "source": [
        "## 4. Model Architecture\n",
        "We design **separate model systems** for node classification and link prediction to prevent task interference.\n",
        "\n",
        "### GraphSAGE System:\n",
        "- `NodeEncoder` + `GraphSAGEClassifier` (with focal loss support)\n",
        "- `LinkEncoder` + `LinkPredictor` (MLP-based)\n",
        "\n",
        "### GATv2 System:\n",
        "- `GATv2Encoder` + `GATv2Classifier` (multi-head attention)\n",
        "- `GATv2LinkEncoder` + `GATv2LinkPredictor` (attention-enhanced)\n",
        "\n",
        "Each system is wrapped in a unified class (`GraphSAGEModels`, `GATv2Models`) for easier training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "825c2bbf",
      "metadata": {
        "id": "825c2bbf"
      },
      "outputs": [],
      "source": [
        "class NodeEncoder(nn.Module):\n",
        "    \"\"\"Encoder specifically for node classification\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb3e6af",
      "metadata": {
        "id": "5eb3e6af"
      },
      "outputs": [],
      "source": [
        "class LinkEncoder(nn.Module):\n",
        "    \"\"\"Encoder specifically optimized for link prediction\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First SAGE layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Second SAGE layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_embeddings(self, x, edge_index):\n",
        "        \"\"\"Get intermediate node embeddings\"\"\"\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.conv1(x, edge_index)\n",
        "            embeddings = F.relu(embeddings)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db5b191",
      "metadata": {
        "id": "2db5b191"
      },
      "outputs": [],
      "source": [
        "class GraphSAGEClassifier(nn.Module):\n",
        "    \"\"\"GraphSAGE with focal loss for handling class imbalance\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, hidden_channels, num_classes, dropout=0.6, gamma=2.0, alpha=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.sage1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.sage2 = SAGEConv(hidden_channels, hidden_channels // 2)\n",
        "        self.sage3 = SAGEConv(hidden_channels // 2, num_classes)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels // 2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Focal loss parameters\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha  # Can be list of per-class weights\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.bn1(self.sage1(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.sage2(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.sage3(x, edge_index)\n",
        "        return x  # Return logits\n",
        "\n",
        "    def focal_loss(self, logits, labels):\n",
        "        \"\"\"Focal loss for imbalanced datasets\"\"\"\n",
        "        ce_loss = F.cross_entropy(logits, labels, reduction=\"none\")\n",
        "        pt = torch.exp(-ce_loss)\n",
        "\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha = self.alpha.to(logits.device)\n",
        "            alpha_weight = alpha[labels]\n",
        "            focal_loss = alpha_weight * focal_loss\n",
        "\n",
        "        return focal_loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3544c918",
      "metadata": {
        "id": "3544c918"
      },
      "outputs": [],
      "source": [
        "# Define the Link Predictor\n",
        "class LinkPredictor(nn.Module):\n",
        "    \"\"\"Link Predictor optimized for GraphSAGE embeddings\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        # GraphSAGE benefits from deeper MLP since embeddings are simpler\n",
        "        self.lin1 = nn.Linear(in_channels * 2, hidden_channels * 2)\n",
        "        self.lin2 = nn.Linear(hidden_channels * 2, hidden_channels)\n",
        "        self.lin3 = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels * 2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, z_src, z_dst):\n",
        "        # Concatenate source and destination embeddings\n",
        "        x = torch.cat([z_src, z_dst], dim=1)\n",
        "\n",
        "        # Deeper MLP suitable for GraphSAGE\n",
        "        x = self.lin1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.lin2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.lin3(x)\n",
        "        return x.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72126b0d",
      "metadata": {
        "id": "72126b0d"
      },
      "outputs": [],
      "source": [
        "class GATv2Encoder(nn.Module):\n",
        "    \"\"\"GATv2 Encoder for node classification\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels, hidden_channels, out_channels, heads=8, dropout=0.2\n",
        "    ):\n",
        "        super().__init__()\n",
        "        from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "        self.conv1 = GATv2Conv(\n",
        "            in_channels, hidden_channels, heads=heads, dropout=dropout, concat=True\n",
        "        )\n",
        "        self.conv2 = GATv2Conv(\n",
        "            hidden_channels * heads,\n",
        "            out_channels,\n",
        "            heads=1,\n",
        "            dropout=dropout,\n",
        "            concat=False,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attention_weights = None  # Store attention weights for analysis\n",
        "\n",
        "    def forward(self, x, edge_index, return_attention=False):\n",
        "        # Store attention weights if requested\n",
        "        x, attn1 = self.conv1(x, edge_index, return_attention_weights=True)\n",
        "        x = F.elu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, attn2 = self.conv2(x, edge_index, return_attention_weights=True)\n",
        "\n",
        "        if return_attention:\n",
        "            self.attention_weights = {\"layer1\": attn1, \"layer2\": attn2}\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d12e747",
      "metadata": {
        "id": "9d12e747"
      },
      "outputs": [],
      "source": [
        "class GATv2LinkEncoder(nn.Module):\n",
        "    \"\"\"GATv2 Encoder specifically optimized for link prediction\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.2\n",
        "    ):\n",
        "        super().__init__()\n",
        "        from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "        # First layer with multiple heads for rich feature extraction\n",
        "        self.conv1 = GATv2Conv(\n",
        "            in_channels, hidden_channels, heads=heads, dropout=dropout, concat=True\n",
        "        )\n",
        "        # Second layer with attention to focus on relevant neighbors for link prediction\n",
        "        self.conv2 = GATv2Conv(\n",
        "            hidden_channels * heads,\n",
        "            hidden_channels,\n",
        "            heads=heads,\n",
        "            dropout=dropout,\n",
        "            concat=True,\n",
        "        )\n",
        "        # Final layer to produce link-focused embeddings\n",
        "        self.conv3 = GATv2Conv(\n",
        "            hidden_channels * heads,\n",
        "            out_channels,\n",
        "            heads=1,\n",
        "            dropout=dropout,\n",
        "            concat=False,\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels * heads)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels * heads)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Layer 1: Initial feature transformation\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x + 1e-8)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Layer 2: Neighborhood aggregation with attention\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.elu(x + 1e-8)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Layer 3: Final embedding for link prediction\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c88cce5",
      "metadata": {
        "id": "2c88cce5"
      },
      "outputs": [],
      "source": [
        "class GATv2LinkPredictor(nn.Module):\n",
        "    \"\"\"Link Predictor optimized for GATv2 embeddings with attention mechanism\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        # GATv2 embeddings are already rich, so we use a shallower network\n",
        "        # with attention-like operations\n",
        "        self.lin_transform = nn.Linear(in_channels * 2, hidden_channels)\n",
        "        self.lin_attention = nn.Linear(hidden_channels, 1)\n",
        "        self.lin_output = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(hidden_channels)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, z_src, z_dst):\n",
        "        # Concatenate embeddings\n",
        "        x = torch.cat([z_src, z_dst], dim=1)\n",
        "\n",
        "        # Transform to hidden space\n",
        "        x = self.lin_transform(x)\n",
        "        x = F.leaky_relu(self.bn(x), negative_slope=0.2)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Attention-like scoring\n",
        "        attention_scores = torch.sigmoid(self.lin_attention(x))\n",
        "        x = x * attention_scores\n",
        "\n",
        "        # Final prediction\n",
        "        x = self.lin_output(x)\n",
        "        return x.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714dbe0c",
      "metadata": {
        "id": "714dbe0c"
      },
      "outputs": [],
      "source": [
        "class GATv2Classifier(nn.Module):\n",
        "    \"\"\"GATv2 classifier with attention mechanisms\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_channels, num_classes, heads=8, dropout=0.2):\n",
        "        super().__init__()\n",
        "        from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "        self.gat1 = GATv2Conv(\n",
        "            hidden_channels, hidden_channels, heads=heads, dropout=dropout, concat=True\n",
        "        )\n",
        "        self.gat2 = GATv2Conv(\n",
        "            hidden_channels * heads,\n",
        "            hidden_channels,\n",
        "            heads=heads,\n",
        "            dropout=dropout,\n",
        "            concat=True,\n",
        "        )\n",
        "        self.gat3 = GATv2Conv(\n",
        "            hidden_channels * heads, num_classes, heads=1, dropout=dropout, concat=False\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels * heads)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels * heads)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.bn1(self.gat1(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.elu(self.bn2(self.gat2(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.gat3(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1cc20b7",
      "metadata": {
        "id": "e1cc20b7"
      },
      "outputs": [],
      "source": [
        "class GraphSAGEModels(nn.Module):\n",
        "    \"\"\"Complete GraphSAGE model system\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Node classification components\n",
        "        self.node_encoder = NodeEncoder(in_channels, hidden_channels, hidden_channels)\n",
        "        self.node_classifier = GraphSAGEClassifier(hidden_channels, num_classes)\n",
        "\n",
        "        # Link prediction components (GraphSAGE optimized)\n",
        "        self.link_encoder = LinkEncoder(in_channels, hidden_channels, hidden_channels)\n",
        "        self.link_predictor = LinkPredictor(\n",
        "            hidden_channels, hidden_channels // 2\n",
        "        )\n",
        "\n",
        "    def forward_node(self, x, edge_index):\n",
        "        \"\"\"Forward pass for node classification\"\"\"\n",
        "        z = self.node_encoder(x, edge_index)\n",
        "        node_logits = self.node_classifier(z, edge_index)\n",
        "        return z, node_logits\n",
        "\n",
        "    def forward_link(self, x, edge_index, edge_label_index=None):\n",
        "        \"\"\"Forward pass for link prediction\"\"\"\n",
        "        z = self.link_encoder(x, edge_index)\n",
        "        if edge_label_index is None:\n",
        "            edge_label_index = edge_index\n",
        "\n",
        "        src = z[edge_label_index[0]]\n",
        "        dst = z[edge_label_index[1]]\n",
        "        link_pred = self.link_predictor(src, dst)\n",
        "\n",
        "        return z, link_pred\n",
        "\n",
        "    def get_node_embeddings(self, x, edge_index):\n",
        "        \"\"\"Get node embeddings for analysis\"\"\"\n",
        "        with torch.no_grad():\n",
        "            z = self.node_encoder(x, edge_index)\n",
        "        return z\n",
        "\n",
        "    def get_link_embeddings(self, x, edge_index):\n",
        "        \"\"\"Get link-focused embeddings\"\"\"\n",
        "        with torch.no_grad():\n",
        "            z = self.link_encoder(x, edge_index)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16424204",
      "metadata": {
        "id": "16424204"
      },
      "outputs": [],
      "source": [
        "class GATv2Models(nn.Module):\n",
        "    \"\"\"Complete GATv2 model system\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes, heads=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # Node classification components\n",
        "        self.node_encoder = GATv2Encoder(\n",
        "            in_channels, hidden_channels, hidden_channels, heads\n",
        "        )\n",
        "        self.node_classifier = GATv2Classifier(hidden_channels, num_classes, heads)\n",
        "\n",
        "        # Link prediction components (GATv2 optimized)\n",
        "        self.link_encoder = GATv2LinkEncoder(\n",
        "            in_channels, hidden_channels, hidden_channels, heads // 2\n",
        "        )\n",
        "        self.link_predictor = GATv2LinkPredictor(hidden_channels, hidden_channels // 2)\n",
        "        # Alternative: self.link_predictor = MultiHeadGATv2LinkPredictor(hidden_channels, hidden_channels // 2)\n",
        "\n",
        "    def forward_node(self, x, edge_index, return_attention=False):\n",
        "        \"\"\"Forward pass for node classification\"\"\"\n",
        "        z = self.node_encoder(x, edge_index, return_attention=return_attention)\n",
        "        node_logits = self.node_classifier(z, edge_index)\n",
        "        return z, node_logits\n",
        "\n",
        "    def forward_link(self, x, edge_index, edge_label_index=None):\n",
        "        \"\"\"Forward pass for link prediction\"\"\"\n",
        "        z = self.link_encoder(x, edge_index)\n",
        "        if edge_label_index is None:\n",
        "            edge_label_index = edge_index\n",
        "\n",
        "        src = z[edge_label_index[0]]\n",
        "        dst = z[edge_label_index[1]]\n",
        "        link_pred = self.link_predictor(src, dst)\n",
        "\n",
        "        return z, link_pred\n",
        "\n",
        "    def get_attention_weights(self, x, edge_index, node_idx=None):\n",
        "        \"\"\"Get attention weights for specific nodes\"\"\"\n",
        "        self.node_encoder.eval()\n",
        "        with torch.no_grad():\n",
        "            _, _ = self.forward_node(x, edge_index, return_attention=True)\n",
        "\n",
        "            if node_idx is not None:\n",
        "                # Extract attention for specific node\n",
        "                attention_data = {}\n",
        "                for layer_name, (\n",
        "                    edge_index_layer,\n",
        "                    attn_weights,\n",
        "                ) in self.node_encoder.attention_weights.items():\n",
        "                    # Find edges where node_idx is the target\n",
        "                    mask = edge_index_layer[1] == node_idx\n",
        "                    attention_data[layer_name] = {\n",
        "                        \"neighbors\": edge_index_layer[0][mask].cpu().numpy(),\n",
        "                        \"weights\": attn_weights[mask].cpu().numpy(),\n",
        "                    }\n",
        "                return attention_data\n",
        "            else:\n",
        "                return self.node_encoder.attention_weights\n",
        "\n",
        "    def get_node_embeddings(self, x, edge_index):\n",
        "        \"\"\"Get node embeddings for analysis\"\"\"\n",
        "        with torch.no_grad():\n",
        "            z, _ = self.forward_node(x, edge_index)\n",
        "        return z\n",
        "\n",
        "    def get_link_embeddings(self, x, edge_index):\n",
        "        \"\"\"Get link-focused embeddings\"\"\"\n",
        "        with torch.no_grad():\n",
        "            z = self.link_encoder(x, edge_index)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8b271b",
      "metadata": {
        "id": "df8b271b"
      },
      "source": [
        "## 5. Data Preparation for Link Prediction\n",
        "\n",
        "For link prediction, we need to:\n",
        "1. Split edges into train/val/test sets\n",
        "2. Create negative examples (non-existent edges)\n",
        "3. Balance positive and negative samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d03f841",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d03f841",
        "outputId": "f6376832-035c-4e35-9ae1-c8a3ac7a2dbb"
      },
      "outputs": [],
      "source": [
        "def prepare_link_prediction_data(data, val_ratio=0.1, test_ratio=0.1):\n",
        "    \"\"\"Prepare data for link prediction task\"\"\"\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Make edges undirected and unique\n",
        "    row, col = edge_index\n",
        "    mask = row < col\n",
        "    row, col = row[mask], col[mask]\n",
        "\n",
        "    n_edges = row.size(0)\n",
        "\n",
        "    # Random permutation\n",
        "    perm = torch.randperm(n_edges)\n",
        "    row, col = row[perm], col[perm]\n",
        "\n",
        "    # Split sizes\n",
        "    n_val = int(n_edges * val_ratio)\n",
        "    n_test = int(n_edges * test_ratio)\n",
        "\n",
        "    # Create splits\n",
        "    val_edges_pos = torch.stack([row[:n_val], col[:n_val]], dim=0)\n",
        "    test_edges_pos = torch.stack(\n",
        "        [row[n_val : n_val + n_test], col[n_val : n_val + n_test]], dim=0\n",
        "    )\n",
        "    train_edges_pos = torch.stack([row[n_val + n_test :], col[n_val + n_test :]], dim=0)\n",
        "\n",
        "    # Training edges (all except test)\n",
        "    train_edge_index = torch.cat([train_edges_pos, val_edges_pos], dim=1)\n",
        "\n",
        "    print(\"Link Prediction Data Split:\")\n",
        "    print(f\"Training edges: {train_edge_index.size(1)}\")\n",
        "    print(f\"Validation positive edges: {val_edges_pos.size(1)}\")\n",
        "    print(f\"Test positive edges: {test_edges_pos.size(1)}\")\n",
        "\n",
        "    return {\n",
        "        \"train_edge_index\": train_edge_index,\n",
        "        \"train_edges_pos\": train_edges_pos,\n",
        "        \"val_edges_pos\": val_edges_pos,\n",
        "        \"test_edges_pos\": test_edges_pos,\n",
        "    }\n",
        "\n",
        "\n",
        "# Prepare link prediction data\n",
        "link_data = prepare_link_prediction_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ad32a9",
      "metadata": {
        "id": "94ad32a9"
      },
      "source": [
        "## 6. Training Functions\n",
        "We define separate training loops for:\n",
        "- `train_graphsage_models`\n",
        "- `train_gatv2_models`\n",
        "\n",
        "Each function:\n",
        "- Trains the node classification module first\n",
        "- Then trains the link prediction module\n",
        "- Uses separate optimizers and loss functions per task\n",
        "- Saves the best model based on validation performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3034723",
      "metadata": {
        "id": "b3034723"
      },
      "outputs": [],
      "source": [
        "def train_graphsage_models(\n",
        "    sage_models, data, link_data, epochs_node=100, epochs_link=100\n",
        "):\n",
        "    \"\"\"Complete training pipeline for GraphSAGE models\"\"\"\n",
        "    print(\"\\nTraining GraphSAGE Model System\\n\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    sage_models = sage_models.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Convert link_data to device\n",
        "    link_data_device = {}\n",
        "    for key, value in link_data.items():\n",
        "        link_data_device[key] = value.to(device)\n",
        "\n",
        "    # Phase 1: Train node classification\n",
        "    print(\"\\n1. Training Node Classification...\")\n",
        "\n",
        "    node_params = list(sage_models.node_encoder.parameters()) + list(\n",
        "        sage_models.node_classifier.parameters()\n",
        "    )\n",
        "    node_optimizer = torch.optim.Adam(node_params, lr=0.01, weight_decay=5e-4)\n",
        "    criterion_node = nn.CrossEntropyLoss()\n",
        "\n",
        "    node_losses, node_accs = [], []\n",
        "    best_node_acc = 0\n",
        "\n",
        "    for epoch in range(epochs_node):\n",
        "        sage_models.node_encoder.train()\n",
        "        sage_models.node_classifier.train()\n",
        "        node_optimizer.zero_grad()\n",
        "\n",
        "        # Forward through GraphSAGE node models\n",
        "        _, node_logits = sage_models.forward_node(data.x, data.edge_index)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion_node(node_logits[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        node_optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        sage_models.node_encoder.eval()\n",
        "        sage_models.node_classifier.eval()\n",
        "        with torch.no_grad():\n",
        "            _, node_logits = sage_models.forward_node(data.x, data.edge_index)\n",
        "            val_pred = node_logits[data.val_mask].argmax(dim=1)\n",
        "            val_acc = (val_pred == data.y[data.val_mask]).float().mean().item()\n",
        "\n",
        "            if val_acc > best_node_acc:\n",
        "                best_node_acc = val_acc\n",
        "                best_node_state = {\n",
        "                    \"encoder\": sage_models.node_encoder.state_dict(),\n",
        "                    \"classifier\": sage_models.node_classifier.state_dict(),\n",
        "                }\n",
        "\n",
        "        node_losses.append(loss.item())\n",
        "        node_accs.append(val_acc)\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f\"Node Epoch {epoch+1:03d}: Loss={loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "    # Load best node model\n",
        "    sage_models.node_encoder.load_state_dict(best_node_state[\"encoder\"])\n",
        "    sage_models.node_classifier.load_state_dict(best_node_state[\"classifier\"])\n",
        "\n",
        "    # Phase 2: Train link prediction\n",
        "    print(\"\\n2. Training Link Prediction...\")\n",
        "\n",
        "    link_params = list(sage_models.link_encoder.parameters()) + list(\n",
        "        sage_models.link_predictor.parameters()\n",
        "    )\n",
        "    link_optimizer = torch.optim.Adam(link_params, lr=0.01, weight_decay=1e-4)\n",
        "    criterion_link = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Prepare training data for link prediction\n",
        "    pos_edges = link_data_device[\"train_edges_pos\"]\n",
        "    neg_edges = negative_sampling(\n",
        "        edge_index=link_data_device[\"train_edge_index\"],\n",
        "        num_nodes=data.num_nodes,\n",
        "        num_neg_samples=pos_edges.size(1),\n",
        "    ).to(device)\n",
        "\n",
        "    train_edges = torch.cat([pos_edges, neg_edges], dim=1)\n",
        "    train_labels = torch.cat(\n",
        "        [\n",
        "            torch.ones(pos_edges.size(1), device=device),\n",
        "            torch.zeros(neg_edges.size(1), device=device),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    link_losses = []\n",
        "\n",
        "    for epoch in range(epochs_link):\n",
        "        sage_models.link_encoder.train()\n",
        "        sage_models.link_predictor.train()\n",
        "        link_optimizer.zero_grad()\n",
        "\n",
        "        # Forward through GraphSAGE link models\n",
        "        _, link_scores = sage_models.forward_link(\n",
        "            data.x, link_data_device[\"train_edge_index\"], train_edges\n",
        "        )\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion_link(link_scores, train_labels)\n",
        "        loss.backward()\n",
        "        link_optimizer.step()\n",
        "\n",
        "        link_losses.append(loss.item())\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f\"Link Epoch {epoch+1:03d}: Loss={loss.item():.4f}\")\n",
        "\n",
        "    print(f\"\\nGraphSAGE Training Completed:\")\n",
        "    print(f\"  Best Node Accuracy: {best_node_acc:.4f}\")\n",
        "    print(f\"  Final Link Loss: {link_losses[-1]:.4f}\")\n",
        "\n",
        "    return sage_models, node_losses, node_accs, link_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39151e29",
      "metadata": {
        "id": "39151e29"
      },
      "outputs": [],
      "source": [
        "def train_gatv2_models(gatv2_models, data, link_data, epochs_node=100, epochs_link=100):\n",
        "    \"\"\"Complete training pipeline for GATv2 models\"\"\"\n",
        "    print(\"\\nTraining GATv2 Model System\\n\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    gatv2_models = gatv2_models.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Convert link_data to device\n",
        "    link_data_device = {}\n",
        "    for key, value in link_data.items():\n",
        "        link_data_device[key] = value.to(device)\n",
        "\n",
        "    # Phase 1: Train node classification with attention\n",
        "    print(\"\\n1. Training Node Classification with Attention...\")\n",
        "\n",
        "    node_params = list(gatv2_models.node_encoder.parameters()) + list(\n",
        "        gatv2_models.node_classifier.parameters()\n",
        "    )\n",
        "    node_optimizer = torch.optim.Adam(node_params, lr=0.005, weight_decay=5e-4)\n",
        "    criterion_node = nn.CrossEntropyLoss()\n",
        "\n",
        "    node_losses, node_accs = [], []\n",
        "    best_node_acc = 0\n",
        "\n",
        "    for epoch in range(epochs_node):\n",
        "        gatv2_models.node_encoder.train()\n",
        "        gatv2_models.node_classifier.train()\n",
        "        node_optimizer.zero_grad()\n",
        "\n",
        "        # Forward through GATv2 node models\n",
        "        _, node_logits = gatv2_models.forward_node(data.x, data.edge_index)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion_node(node_logits[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        node_optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        gatv2_models.node_encoder.eval()\n",
        "        gatv2_models.node_classifier.eval()\n",
        "        with torch.no_grad():\n",
        "            _, node_logits = gatv2_models.forward_node(data.x, data.edge_index)\n",
        "            val_pred = node_logits[data.val_mask].argmax(dim=1)\n",
        "            val_acc = (val_pred == data.y[data.val_mask]).float().mean().item()\n",
        "\n",
        "            if val_acc > best_node_acc:\n",
        "                best_node_acc = val_acc\n",
        "                best_node_state = {\n",
        "                    \"encoder\": gatv2_models.node_encoder.state_dict(),\n",
        "                    \"classifier\": gatv2_models.node_classifier.state_dict(),\n",
        "                }\n",
        "\n",
        "        node_losses.append(loss.item())\n",
        "        node_accs.append(val_acc)\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f\"Node Epoch {epoch+1:03d}: Loss={loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "    # Load best node model\n",
        "    gatv2_models.node_encoder.load_state_dict(best_node_state[\"encoder\"])\n",
        "    gatv2_models.node_classifier.load_state_dict(best_node_state[\"classifier\"])\n",
        "\n",
        "    # Phase 2: Train link prediction with attention-based predictor\n",
        "    print(\"\\n2. Training Link Prediction with Attention Mechanisms...\")\n",
        "\n",
        "    link_params = list(gatv2_models.link_encoder.parameters()) + list(\n",
        "        gatv2_models.link_predictor.parameters()\n",
        "    )\n",
        "    link_optimizer = torch.optim.Adam(link_params, lr=0.005, weight_decay=1e-4)\n",
        "    criterion_link = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Prepare training data for link prediction\n",
        "    pos_edges = link_data_device[\"train_edges_pos\"]\n",
        "    neg_edges = negative_sampling(\n",
        "        edge_index=link_data_device[\"train_edge_index\"],\n",
        "        num_nodes=data.num_nodes,\n",
        "        num_neg_samples=pos_edges.size(1),\n",
        "    ).to(device)\n",
        "\n",
        "    train_edges = torch.cat([pos_edges, neg_edges], dim=1)\n",
        "    train_labels = torch.cat(\n",
        "        [\n",
        "            torch.ones(pos_edges.size(1), device=device),\n",
        "            torch.zeros(neg_edges.size(1), device=device),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    link_losses = []\n",
        "\n",
        "    for epoch in range(epochs_link):\n",
        "        gatv2_models.link_encoder.train()\n",
        "        gatv2_models.link_predictor.train()\n",
        "        link_optimizer.zero_grad()\n",
        "\n",
        "        # Forward through GATv2 link models\n",
        "        _, link_scores = gatv2_models.forward_link(\n",
        "            data.x, link_data_device[\"train_edge_index\"], train_edges\n",
        "        )\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion_link(link_scores, train_labels)\n",
        "        loss.backward()\n",
        "        link_optimizer.step()\n",
        "\n",
        "        link_losses.append(loss.item())\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f\"Link Epoch {epoch+1:03d}: Loss={loss.item():.4f}\")\n",
        "\n",
        "    print(f\"\\nGATv2 Training Completed:\")\n",
        "    print(f\"  Best Node Accuracy: {best_node_acc:.4f}\")\n",
        "    print(f\"  Final Link Loss: {link_losses[-1]:.4f}\")\n",
        "\n",
        "    return gatv2_models, node_losses, node_accs, link_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ef7fab",
      "metadata": {},
      "source": [
        "## 7. Evaluation Functions\n",
        "We evaluate both tasks:\n",
        "- **Node classification**: Accuracy on test set\n",
        "- **Link prediction**: AUC-ROC, Average Precision (AP), Precision@k\n",
        "\n",
        "Evaluation functions:\n",
        "- `evaluate_graphsage_models`\n",
        "- `evaluate_gatv2_models`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ebee9a",
      "metadata": {
        "id": "e4ebee9a"
      },
      "outputs": [],
      "source": [
        "def evaluate_graphsage_models(sage_models, data, link_data):\n",
        "    \"\"\"Evaluate GraphSAGE models on both tasks\"\"\"\n",
        "    sage_models.eval()\n",
        "    device = data.x.device  # Get the device from data\n",
        "\n",
        "    # Convert link_data to the same device\n",
        "    link_data_device = {}\n",
        "    for key, value in link_data.items():\n",
        "        link_data_device[key] = value.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Node Classification Evaluation\n",
        "        _, node_logits = sage_models.forward_node(data.x, data.edge_index)\n",
        "        test_pred = node_logits[data.test_mask].argmax(dim=1)\n",
        "        node_acc = (test_pred == data.y[data.test_mask]).float().mean().item()\n",
        "\n",
        "        # Link Prediction Evaluation\n",
        "        z = sage_models.get_link_embeddings(data.x, link_data_device[\"train_edge_index\"])\n",
        "\n",
        "        # Positive test edges\n",
        "        pos_edges = link_data_device[\"test_edges_pos\"]\n",
        "        src_pos = z[pos_edges[0]]\n",
        "        dst_pos = z[pos_edges[1]]\n",
        "        pos_scores = torch.sigmoid(sage_models.link_predictor(src_pos, dst_pos))\n",
        "\n",
        "        # Negative test edges\n",
        "        neg_edges = negative_sampling(\n",
        "            edge_index=torch.cat(\n",
        "                [link_data_device[\"train_edge_index\"], link_data_device[\"val_edges_pos\"]], dim=1\n",
        "            ),\n",
        "            num_nodes=data.num_nodes,\n",
        "            num_neg_samples=pos_edges.size(1),\n",
        "        ).to(device)\n",
        "\n",
        "        src_neg = z[neg_edges[0]]\n",
        "        dst_neg = z[neg_edges[1]]\n",
        "        neg_scores = torch.sigmoid(sage_models.link_predictor(src_neg, dst_neg))\n",
        "\n",
        "        # Combine predictions\n",
        "        all_scores = torch.cat([pos_scores, neg_scores]).cpu().numpy()\n",
        "        all_labels = torch.cat([\n",
        "            torch.ones(pos_scores.size(0), device=device),\n",
        "            torch.zeros(neg_scores.size(0), device=device)\n",
        "        ]).cpu().numpy()\n",
        "\n",
        "        # Compute metrics\n",
        "        auc = roc_auc_score(all_labels, all_scores)\n",
        "        ap = average_precision_score(all_labels, all_scores)\n",
        "\n",
        "        # Precision@k\n",
        "        k = min(100, len(all_scores) // 2)\n",
        "        top_k_idx = np.argsort(all_scores)[-k:]\n",
        "        precision_at_k = all_labels[top_k_idx].mean()\n",
        "\n",
        "    return {\n",
        "        'node_accuracy': node_acc,\n",
        "        'link_auc': auc,\n",
        "        'link_ap': ap,\n",
        "        'link_precision_at_k': precision_at_k\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2133417",
      "metadata": {
        "id": "f2133417"
      },
      "outputs": [],
      "source": [
        "def evaluate_gatv2_models(gatv2_models, data, link_data):\n",
        "    \"\"\"Evaluate GATv2 models on both tasks\"\"\"\n",
        "    gatv2_models.eval()\n",
        "    device = data.x.device  # Get the device from data\n",
        "\n",
        "    # Convert link_data to the same device\n",
        "    link_data_device = {}\n",
        "    for key, value in link_data.items():\n",
        "        link_data_device[key] = value.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Node Classification Evaluation\n",
        "        _, node_logits = gatv2_models.forward_node(data.x, data.edge_index)\n",
        "        test_pred = node_logits[data.test_mask].argmax(dim=1)\n",
        "        node_acc = (test_pred == data.y[data.test_mask]).float().mean().item()\n",
        "\n",
        "        # Link Prediction Evaluation\n",
        "        z = gatv2_models.get_link_embeddings(data.x, link_data_device[\"train_edge_index\"])\n",
        "\n",
        "        # Positive test edges\n",
        "        pos_edges = link_data_device[\"test_edges_pos\"]\n",
        "        src_pos = z[pos_edges[0]]\n",
        "        dst_pos = z[pos_edges[1]]\n",
        "        pos_scores = torch.sigmoid(gatv2_models.link_predictor(src_pos, dst_pos))\n",
        "\n",
        "        # Negative test edges\n",
        "        neg_edges = negative_sampling(\n",
        "            edge_index=torch.cat(\n",
        "                [link_data_device[\"train_edge_index\"], link_data_device[\"val_edges_pos\"]], dim=1\n",
        "            ),\n",
        "            num_nodes=data.num_nodes,\n",
        "            num_neg_samples=pos_edges.size(1),\n",
        "        ).to(device)\n",
        "\n",
        "        src_neg = z[neg_edges[0]]\n",
        "        dst_neg = z[neg_edges[1]]\n",
        "        neg_scores = torch.sigmoid(gatv2_models.link_predictor(src_neg, dst_neg))\n",
        "\n",
        "        # Combine predictions\n",
        "        all_scores = torch.cat([pos_scores, neg_scores]).cpu().numpy()\n",
        "        all_labels = torch.cat([\n",
        "            torch.ones(pos_scores.size(0), device=device),\n",
        "            torch.zeros(neg_scores.size(0), device=device)\n",
        "        ]).cpu().numpy()\n",
        "\n",
        "        # Compute metrics\n",
        "        auc = roc_auc_score(all_labels, all_scores)\n",
        "        ap = average_precision_score(all_labels, all_scores)\n",
        "\n",
        "        # Precision@k\n",
        "        k = min(100, len(all_scores) // 2)\n",
        "        top_k_idx = np.argsort(all_scores)[-k:]\n",
        "        precision_at_k = all_labels[top_k_idx].mean()\n",
        "\n",
        "    return {\n",
        "        'node_accuracy': node_acc,\n",
        "        'link_auc': auc,\n",
        "        'link_ap': ap,\n",
        "        'link_precision_at_k': precision_at_k\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb1c2a7",
      "metadata": {
        "id": "7fb1c2a7"
      },
      "source": [
        "## 8. Model Initialization\n",
        "We initialize both GraphSAGE and GATv2 model systems, print their parameter counts, and compare architectural complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QuyU6MuJPKFD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuyU6MuJPKFD",
        "outputId": "7b1aba5a-74e8-48a4-f9fc-a3c62f21babd"
      },
      "outputs": [],
      "source": [
        "# Initialize both model systems\n",
        "print(\"Initializing GraphSAGE and GATv2 model systems...\")\n",
        "\n",
        "# GraphSAGE models\n",
        "sage_models = GraphSAGEModels(\n",
        "    in_channels=data.num_features, hidden_channels=128, num_classes=dataset.num_classes\n",
        ")\n",
        "\n",
        "# GATv2 models\n",
        "gatv2_models = GATv2Models(\n",
        "    in_channels=data.num_features,\n",
        "    hidden_channels=128,\n",
        "    num_classes=dataset.num_classes,\n",
        "    heads=8,\n",
        ")\n",
        "\n",
        "print(f\"\\nModel Parameter Counts:\")\n",
        "print(\n",
        "    f\"GraphSAGE Total Parameters: {sum(p.numel() for p in sage_models.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Node Encoder: {sum(p.numel() for p in sage_models.node_encoder.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Node Classifier: {sum(p.numel() for p in sage_models.node_classifier.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Link Encoder: {sum(p.numel() for p in sage_models.link_encoder.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Link Predictor: {sum(p.numel() for p in sage_models.link_predictor.parameters()):,}\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"\\nGATv2 Total Parameters: {sum(p.numel() for p in gatv2_models.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Node Encoder: {sum(p.numel() for p in gatv2_models.node_encoder.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Node Classifier: {sum(p.numel() for p in gatv2_models.node_classifier.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Link Encoder: {sum(p.numel() for p in gatv2_models.link_encoder.parameters()):,}\"\n",
        ")\n",
        "print(\n",
        "    f\"  Link Predictor: {sum(p.numel() for p in gatv2_models.link_predictor.parameters()):,}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b81f1d",
      "metadata": {},
      "source": [
        "## 9. Comparative Analysis: Multi-Run Experiment\n",
        "We run **100 independent training sessions** for each model to:\n",
        "- Measure performance stability\n",
        "- Compare average accuracy, AUC, training time\n",
        "- Perform statistical significance tests (paired t-tests)\n",
        "- Visualize distributions, learning curves, and performance trade-offs\n",
        "\n",
        "Key outputs:\n",
        "- Summary table of mean  std metrics\n",
        "- Box plots of accuracy and AUC distributions\n",
        "- Learning curves with standard deviation bands\n",
        "- Pareto frontier analysis (Accuracy vs. AUC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dBXHEp8HWGGM",
      "metadata": {
        "id": "dBXHEp8HWGGM"
      },
      "outputs": [],
      "source": [
        "def plot_multiple_runs_results(all_results, training_times, num_runs):\n",
        "    \"\"\"Visualize results from multiple runs\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # 1. Node Accuracy Distribution\n",
        "    ax = axes[0, 0]\n",
        "    positions = [1, 2]\n",
        "    sage_accs = all_results[\"GraphSAGE\"][\"node_accuracies\"]\n",
        "    gatv2_accs = all_results[\"GATv2\"][\"node_accuracies\"]\n",
        "\n",
        "    bp = ax.boxplot(\n",
        "        [sage_accs, gatv2_accs], positions=positions, widths=0.6, patch_artist=True\n",
        "    )\n",
        "\n",
        "    # Color boxes\n",
        "    colors = [\"tab:blue\", \"tab:orange\"]\n",
        "    for patch, color in zip(bp[\"boxes\"], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    ax.set_xticks(positions)\n",
        "    ax.set_xticklabels([\"GraphSAGE\", \"GATv2\"])\n",
        "    ax.set_title(\n",
        "        f\"Node Accuracy Distribution\\n({num_runs} runs)\", fontsize=12, fontweight=\"bold\"\n",
        "    )\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
        "\n",
        "    # Add mean points\n",
        "    ax.scatter(\n",
        "        [1], [np.mean(sage_accs)], color=\"darkblue\", s=100, marker=\"D\", label=\"Mean\"\n",
        "    )\n",
        "    ax.scatter([2], [np.mean(gatv2_accs)], color=\"darkorange\", s=100, marker=\"D\")\n",
        "\n",
        "    # 2. Link AUC Distribution\n",
        "    ax = axes[0, 1]\n",
        "    sage_aucs = all_results[\"GraphSAGE\"][\"link_aucs\"]\n",
        "    gatv2_aucs = all_results[\"GATv2\"][\"link_aucs\"]\n",
        "\n",
        "    bp = ax.boxplot(\n",
        "        [sage_aucs, gatv2_aucs], positions=positions, widths=0.6, patch_artist=True\n",
        "    )\n",
        "\n",
        "    for patch, color in zip(bp[\"boxes\"], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    ax.set_xticks(positions)\n",
        "    ax.set_xticklabels([\"GraphSAGE\", \"GATv2\"])\n",
        "    ax.set_title(\n",
        "        f\"Link Prediction AUC Distribution\\n({num_runs} runs)\", fontsize=12, fontweight=\"bold\"\n",
        "    )\n",
        "    ax.set_ylabel(\"AUC-ROC\")\n",
        "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
        "\n",
        "    # Add mean points\n",
        "    ax.scatter([1], [np.mean(sage_aucs)], color=\"darkblue\", s=100, marker=\"D\")\n",
        "    ax.scatter([2], [np.mean(gatv2_aucs)], color=\"darkorange\", s=100, marker=\"D\")\n",
        "\n",
        "    # 3. Training Time Comparison\n",
        "    ax = axes[0, 2]\n",
        "    sage_times = training_times[\"GraphSAGE\"]\n",
        "    gatv2_times = training_times[\"GATv2\"]\n",
        "\n",
        "    bp = ax.boxplot(\n",
        "        [sage_times, gatv2_times], positions=positions, widths=0.6, patch_artist=True\n",
        "    )\n",
        "\n",
        "    for patch, color in zip(bp[\"boxes\"], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    ax.set_xticks(positions)\n",
        "    ax.set_xticklabels([\"GraphSAGE\", \"GATv2\"])\n",
        "    ax.set_title(\n",
        "        f\"Training Time Distribution\\n({num_runs} runs)\", fontsize=12, fontweight=\"bold\"\n",
        "    )\n",
        "    ax.set_ylabel(\"Time (seconds)\")\n",
        "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
        "\n",
        "    # Add mean points\n",
        "    ax.scatter([1], [np.mean(sage_times)], color=\"darkblue\", s=100, marker=\"D\")\n",
        "    ax.scatter([2], [np.mean(gatv2_times)], color=\"darkorange\", s=100, marker=\"D\")\n",
        "\n",
        "    # 4. Average Training Curves (Node Loss)\n",
        "    ax = axes[1, 0]\n",
        "\n",
        "    # Get average node losses across runs\n",
        "    max_len = max(\n",
        "        len(losses) for losses in all_results[\"GraphSAGE\"][\"node_losses_list\"]\n",
        "    )\n",
        "\n",
        "    # Pad and average GraphSAGE losses\n",
        "    sage_losses_padded = []\n",
        "    for losses in all_results[\"GraphSAGE\"][\"node_losses_list\"]:\n",
        "        if len(losses) < max_len:\n",
        "            losses = np.pad(losses, (0, max_len - len(losses)), \"edge\")\n",
        "        sage_losses_padded.append(losses)\n",
        "\n",
        "    sage_losses_mean = np.mean(sage_losses_padded, axis=0)\n",
        "    sage_losses_std = np.std(sage_losses_padded, axis=0)\n",
        "\n",
        "    # Pad and average GATv2 losses\n",
        "    gatv2_losses_padded = []\n",
        "    for losses in all_results[\"GATv2\"][\"node_losses_list\"]:\n",
        "        if len(losses) < max_len:\n",
        "            losses = np.pad(losses, (0, max_len - len(losses)), \"edge\")\n",
        "        gatv2_losses_padded.append(losses)\n",
        "\n",
        "    gatv2_losses_mean = np.mean(gatv2_losses_padded, axis=0)\n",
        "    gatv2_losses_std = np.std(gatv2_losses_padded, axis=0)\n",
        "\n",
        "    epochs = np.arange(len(sage_losses_mean))\n",
        "\n",
        "    ax.plot(epochs, sage_losses_mean, label=\"GraphSAGE\", color=\"tab:blue\", linewidth=2)\n",
        "    ax.fill_between(\n",
        "        epochs,\n",
        "        sage_losses_mean - sage_losses_std,\n",
        "        sage_losses_mean + sage_losses_std,\n",
        "        alpha=0.2,\n",
        "        color=\"tab:blue\",\n",
        "    )\n",
        "\n",
        "    ax.plot(epochs, gatv2_losses_mean, label=\"GATv2\", color=\"tab:orange\", linewidth=2)\n",
        "    ax.fill_between(\n",
        "        epochs,\n",
        "        gatv2_losses_mean - gatv2_losses_std,\n",
        "        gatv2_losses_mean + gatv2_losses_std,\n",
        "        alpha=0.2,\n",
        "        color=\"tab:orange\",\n",
        "    )\n",
        "\n",
        "    ax.set_title(\n",
        "        \"Average Node Classification Loss\\n(with std deviation)\",\n",
        "        fontsize=12,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. Average Training Curves (Link Loss)\n",
        "    ax = axes[1, 1]\n",
        "\n",
        "    # Get average link losses across runs\n",
        "    max_len = max(\n",
        "        len(losses) for losses in all_results[\"GraphSAGE\"][\"link_losses_list\"]\n",
        "    )\n",
        "\n",
        "    # Pad and average GraphSAGE losses\n",
        "    sage_losses_padded = []\n",
        "    for losses in all_results[\"GraphSAGE\"][\"link_losses_list\"]:\n",
        "        if len(losses) < max_len:\n",
        "            losses = np.pad(losses, (0, max_len - len(losses)), \"edge\")\n",
        "        sage_losses_padded.append(losses)\n",
        "\n",
        "    sage_losses_mean = np.mean(sage_losses_padded, axis=0)\n",
        "    sage_losses_std = np.std(sage_losses_padded, axis=0)\n",
        "\n",
        "    # Pad and average GATv2 losses\n",
        "    gatv2_losses_padded = []\n",
        "    for losses in all_results[\"GATv2\"][\"link_losses_list\"]:\n",
        "        if len(losses) < max_len:\n",
        "            losses = np.pad(losses, (0, max_len - len(losses)), \"edge\")\n",
        "        gatv2_losses_padded.append(losses)\n",
        "\n",
        "    gatv2_losses_mean = np.mean(gatv2_losses_padded, axis=0)\n",
        "    gatv2_losses_std = np.std(gatv2_losses_padded, axis=0)\n",
        "\n",
        "    epochs = np.arange(len(sage_losses_mean))\n",
        "\n",
        "    ax.plot(epochs, sage_losses_mean, label=\"GraphSAGE\", color=\"tab:blue\", linewidth=2)\n",
        "    ax.fill_between(\n",
        "        epochs,\n",
        "        sage_losses_mean - sage_losses_std,\n",
        "        sage_losses_mean + sage_losses_std,\n",
        "        alpha=0.2,\n",
        "        color=\"tab:blue\",\n",
        "    )\n",
        "\n",
        "    ax.plot(epochs, gatv2_losses_mean, label=\"GATv2\", color=\"tab:orange\", linewidth=2)\n",
        "    ax.fill_between(\n",
        "        epochs,\n",
        "        gatv2_losses_mean - gatv2_losses_std,\n",
        "        gatv2_losses_mean + gatv2_losses_std,\n",
        "        alpha=0.2,\n",
        "        color=\"tab:orange\",\n",
        "    )\n",
        "\n",
        "    ax.set_title(\n",
        "        \"Average Link Prediction Loss\\n(with std deviation)\",\n",
        "        fontsize=12,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. Performance Trade-off Analysis\n",
        "    ax = axes[1, 2]\n",
        "\n",
        "    # Scatter plot: Node Accuracy vs Link AUC\n",
        "    sage_accs = np.array(all_results[\"GraphSAGE\"][\"node_accuracies\"])\n",
        "    sage_aucs = np.array(all_results[\"GraphSAGE\"][\"link_aucs\"])\n",
        "    gatv2_accs = np.array(all_results[\"GATv2\"][\"node_accuracies\"])\n",
        "    gatv2_aucs = np.array(all_results[\"GATv2\"][\"link_aucs\"])\n",
        "\n",
        "    ax.scatter(\n",
        "        sage_accs,\n",
        "        sage_aucs,\n",
        "        color=\"tab:blue\",\n",
        "        s=100,\n",
        "        alpha=0.7,\n",
        "        label=\"GraphSAGE\",\n",
        "        edgecolors=\"darkblue\",\n",
        "        linewidth=1,\n",
        "    )\n",
        "    ax.scatter(\n",
        "        gatv2_accs,\n",
        "        gatv2_aucs,\n",
        "        color=\"tab:orange\",\n",
        "        s=100,\n",
        "        alpha=0.7,\n",
        "        label=\"GATv2\",\n",
        "        edgecolors=\"darkorange\",\n",
        "        linewidth=1,\n",
        "    )\n",
        "\n",
        "    # Add mean points\n",
        "    ax.scatter(\n",
        "        np.mean(sage_accs),\n",
        "        np.mean(sage_aucs),\n",
        "        color=\"darkblue\",\n",
        "        s=200,\n",
        "        marker=\"*\",\n",
        "        label=\"GraphSAGE Mean\",\n",
        "    )\n",
        "    ax.scatter(\n",
        "        np.mean(gatv2_accs),\n",
        "        np.mean(gatv2_aucs),\n",
        "        color=\"darkorange\",\n",
        "        s=200,\n",
        "        marker=\"*\",\n",
        "        label=\"GATv2 Mean\",\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel(\"Node Accuracy\")\n",
        "    ax.set_ylabel(\"Link Prediction AUC\")\n",
        "    ax.set_title(\n",
        "        \"Performance Trade-off Analysis\\n(Each point = 1 run)\",\n",
        "        fontsize=12,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add Pareto frontier\n",
        "    all_accs = np.concatenate([sage_accs, gatv2_accs])\n",
        "    all_aucs = np.concatenate([sage_aucs, gatv2_aucs])\n",
        "\n",
        "    # Simple Pareto frontier\n",
        "    pareto_mask = np.ones(len(all_accs), dtype=bool)\n",
        "    for i in range(len(all_accs)):\n",
        "        for j in range(len(all_accs)):\n",
        "            if i != j and all_accs[j] >= all_accs[i] and all_aucs[j] >= all_aucs[i]:\n",
        "                pareto_mask[i] = False\n",
        "                break\n",
        "\n",
        "    pareto_accs = all_accs[pareto_mask]\n",
        "    pareto_aucs = all_aucs[pareto_mask]\n",
        "\n",
        "    # Sort for plotting\n",
        "    sort_idx = np.argsort(pareto_accs)\n",
        "    ax.plot(\n",
        "        pareto_accs[sort_idx],\n",
        "        pareto_aucs[sort_idx],\n",
        "        \"k--\",\n",
        "        alpha=0.5,\n",
        "        linewidth=1,\n",
        "        label=\"Pareto Frontier\",\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"images/multiple_runs_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FT-k0zzcV9Ld",
      "metadata": {
        "id": "FT-k0zzcV9Ld"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def run_multiple_experiments(\n",
        "    data, link_data, num_runs=100, epochs_node=80, epochs_link=120\n",
        "):\n",
        "    \"\"\"Run multiple independent training sessions and collect statistics\"\"\"\n",
        "\n",
        "    print(f\"\\nRunning {num_runs} Independent Experiments\")\n",
        "    print(f\"GraphSAGE vs GATv2 - Averaging Results\\n\")\n",
        "\n",
        "    # Storage for results\n",
        "    all_results = {\n",
        "        \"GraphSAGE\": {\n",
        "            \"node_accuracies\": [],\n",
        "            \"link_aucs\": [],\n",
        "            \"link_aps\": [],\n",
        "            \"precisions_at_k\": [],\n",
        "            \"node_losses_list\": [],\n",
        "            \"link_losses_list\": [],\n",
        "        },\n",
        "        \"GATv2\": {\n",
        "            \"node_accuracies\": [],\n",
        "            \"link_aucs\": [],\n",
        "            \"link_aps\": [],\n",
        "            \"precisions_at_k\": [],\n",
        "            \"node_losses_list\": [],\n",
        "            \"link_losses_list\": [],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    training_times = {\"GraphSAGE\": [], \"GATv2\": []}\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"\\nExperiment Run {run+1}/{num_runs}\\n\")\n",
        "\n",
        "        # Set different random seed for each run\n",
        "        torch.manual_seed(42 + run)\n",
        "        np.random.seed(42 + run)\n",
        "\n",
        "        print(f\"\\n[Run {run+1}] Training GraphSAGE...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Reinitialize fresh GraphSAGE models\n",
        "        sage_models = GraphSAGEModels(\n",
        "            in_channels=data.num_features,\n",
        "            hidden_channels=128,\n",
        "            num_classes=dataset.num_classes,\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        sage_models, sage_node_losses, sage_node_accs, sage_link_losses = (\n",
        "            train_graphsage_models(\n",
        "                sage_models,\n",
        "                data,\n",
        "                link_data,\n",
        "                epochs_node=epochs_node,\n",
        "                epochs_link=epochs_link,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        sage_metrics = evaluate_graphsage_models(sage_models, data, link_data)\n",
        "        sage_time = time.time() - start_time\n",
        "        training_times[\"GraphSAGE\"].append(sage_time)\n",
        "\n",
        "        # Store results\n",
        "        all_results[\"GraphSAGE\"][\"node_accuracies\"].append(\n",
        "            sage_metrics[\"node_accuracy\"]\n",
        "        )\n",
        "        all_results[\"GraphSAGE\"][\"link_aucs\"].append(sage_metrics[\"link_auc\"])\n",
        "        all_results[\"GraphSAGE\"][\"link_aps\"].append(sage_metrics[\"link_ap\"])\n",
        "        all_results[\"GraphSAGE\"][\"precisions_at_k\"].append(\n",
        "            sage_metrics[\"link_precision_at_k\"]\n",
        "        )\n",
        "        all_results[\"GraphSAGE\"][\"node_losses_list\"].append(sage_node_losses)\n",
        "        all_results[\"GraphSAGE\"][\"link_losses_list\"].append(sage_link_losses)\n",
        "\n",
        "        print(\n",
        "            f\"GraphSAGE Run {run+1}: Node Acc={sage_metrics['node_accuracy']:.4f}, \"\n",
        "            f\"Link AUC={sage_metrics['link_auc']:.4f}, Time={sage_time:.1f}s\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\n[Run {run+1}] Training GATv2...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Reinitialize fresh GATv2 models\n",
        "        gatv2_models = GATv2Models(\n",
        "            in_channels=data.num_features,\n",
        "            hidden_channels=128,\n",
        "            num_classes=dataset.num_classes,\n",
        "            heads=8,\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        gatv2_models, gatv2_node_losses, gatv2_node_accs, gatv2_link_losses = (\n",
        "            train_gatv2_models(\n",
        "                gatv2_models,\n",
        "                data,\n",
        "                link_data,\n",
        "                epochs_node=epochs_node,\n",
        "                epochs_link=epochs_link,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        gatv2_metrics = evaluate_gatv2_models(gatv2_models, data, link_data)\n",
        "        gatv2_time = time.time() - start_time\n",
        "        training_times[\"GATv2\"].append(gatv2_time)\n",
        "\n",
        "        # Store results\n",
        "        all_results[\"GATv2\"][\"node_accuracies\"].append(gatv2_metrics[\"node_accuracy\"])\n",
        "        all_results[\"GATv2\"][\"link_aucs\"].append(gatv2_metrics[\"link_auc\"])\n",
        "        all_results[\"GATv2\"][\"link_aps\"].append(gatv2_metrics[\"link_ap\"])\n",
        "        all_results[\"GATv2\"][\"precisions_at_k\"].append(\n",
        "            gatv2_metrics[\"link_precision_at_k\"]\n",
        "        )\n",
        "        all_results[\"GATv2\"][\"node_losses_list\"].append(gatv2_node_losses)\n",
        "        all_results[\"GATv2\"][\"link_losses_list\"].append(gatv2_link_losses)\n",
        "\n",
        "        print(\n",
        "            f\"GATv2 Run {run+1}: Node Acc={gatv2_metrics['node_accuracy']:.4f}, \"\n",
        "            f\"Link AUC={gatv2_metrics['link_auc']:.4f}, Time={gatv2_time:.1f}s\"\n",
        "        )\n",
        "\n",
        "        # Clean up to free memory\n",
        "        del sage_models, gatv2_models\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nAnalysis (Mean  Std over {num_runs} runs)\\n\")\n",
        "\n",
        "    def compute_stats(values):\n",
        "        mean = np.mean(values)\n",
        "        std = np.std(values)\n",
        "        min_val = np.min(values)\n",
        "        max_val = np.max(values)\n",
        "        return mean, std, min_val, max_val\n",
        "\n",
        "    # Create summary table\n",
        "    summary_data = []\n",
        "\n",
        "    for model_name in [\"GraphSAGE\", \"GATv2\"]:\n",
        "        # Node Accuracy\n",
        "        node_mean, node_std, node_min, node_max = compute_stats(\n",
        "            all_results[model_name][\"node_accuracies\"]\n",
        "        )\n",
        "\n",
        "        # Link AUC\n",
        "        auc_mean, auc_std, auc_min, auc_max = compute_stats(\n",
        "            all_results[model_name][\"link_aucs\"]\n",
        "        )\n",
        "\n",
        "        # Link AP\n",
        "        ap_mean, ap_std, ap_min, ap_max = compute_stats(\n",
        "            all_results[model_name][\"link_aps\"]\n",
        "        )\n",
        "\n",
        "        # Precision@k\n",
        "        prec_mean, prec_std, prec_min, prec_max = compute_stats(\n",
        "            all_results[model_name][\"precisions_at_k\"]\n",
        "        )\n",
        "\n",
        "        # Training time\n",
        "        time_mean, time_std, time_min, time_max = compute_stats(\n",
        "            training_times[model_name]\n",
        "        )\n",
        "\n",
        "        summary_data.append(\n",
        "            {\n",
        "                \"Model\": model_name,\n",
        "                \"Node Accuracy\": f\"{node_mean:.4f}  {node_std:.4f} [{node_min:.4f}-{node_max:.4f}]\",\n",
        "                \"Link AUC\": f\"{auc_mean:.4f}  {auc_std:.4f} [{auc_min:.4f}-{auc_max:.4f}]\",\n",
        "                \"Link AP\": f\"{ap_mean:.4f}  {ap_std:.4f} [{ap_min:.4f}-{ap_max:.4f}]\",\n",
        "                \"Precision@100\": f\"{prec_mean:.4f}  {prec_std:.4f} [{prec_min:.4f}-{prec_max:.4f}]\",\n",
        "                \"Training Time (s)\": f\"{time_mean:.1f}  {time_std:.1f} [{time_min:.1f}-{time_max:.1f}]\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # Display summary table\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(\"\\n\" + summary_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\nComparison\\n\")\n",
        "\n",
        "    from scipy import stats\n",
        "\n",
        "    # Compare metrics between models\n",
        "    for metric_name, sage_values, gatv2_values in [\n",
        "        (\n",
        "            \"Node Accuracy\",\n",
        "            all_results[\"GraphSAGE\"][\"node_accuracies\"],\n",
        "            all_results[\"GATv2\"][\"node_accuracies\"],\n",
        "        ),\n",
        "        (\n",
        "            \"Link AUC\",\n",
        "            all_results[\"GraphSAGE\"][\"link_aucs\"],\n",
        "            all_results[\"GATv2\"][\"link_aucs\"],\n",
        "        ),\n",
        "        (\n",
        "            \"Link AP\",\n",
        "            all_results[\"GraphSAGE\"][\"link_aps\"],\n",
        "            all_results[\"GATv2\"][\"link_aps\"],\n",
        "        ),\n",
        "    ]:\n",
        "        # T-test for statistical significance\n",
        "        t_stat, p_value = stats.ttest_rel(sage_values, gatv2_values)\n",
        "\n",
        "        sage_mean = np.mean(sage_values)\n",
        "        gatv2_mean = np.mean(gatv2_values)\n",
        "        diff = gatv2_mean - sage_mean\n",
        "\n",
        "        print(f\"\\n{metric_name}:\")\n",
        "        print(f\"  GraphSAGE: {sage_mean:.4f}  {np.std(sage_values):.4f}\")\n",
        "        print(f\"  GATv2:     {gatv2_mean:.4f}  {np.std(gatv2_values):.4f}\")\n",
        "        print(f\"  Difference: {diff:.4f} (GATv2 - GraphSAGE)\")\n",
        "        print(f\"  p-value: {p_value:.6f}\")\n",
        "\n",
        "        if p_value < 0.05:\n",
        "            if diff > 0:\n",
        "                print(f\"   GATv2 is significantly better (p < 0.05)\")\n",
        "            else:\n",
        "                print(f\"   GraphSAGE is significantly better (p < 0.05)\")\n",
        "        else:\n",
        "            print(f\"   No significant difference (p  0.05)\")\n",
        "\n",
        "    print(f\"visualizing results across {num_runs} runs\")\n",
        "\n",
        "    plot_multiple_runs_results(all_results, training_times, num_runs)\n",
        "\n",
        "    return all_results, summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EvORywlLWCM9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EvORywlLWCM9",
        "outputId": "f54a8cee-b663-496f-c7be-bd2fc5aedd2c"
      },
      "outputs": [],
      "source": [
        "all_results, summary_df = run_multiple_experiments(\n",
        "    data, link_data, num_runs=100, epochs_node=60, epochs_link=120\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
